{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readh5(filename, datasetname='main', rr=[1,1,1]):\n",
    "    fid=h5py.File(filename,'r')\n",
    "    if isinstance(datasetname, (list,)):\n",
    "        out = [None] *len(datasetname)\n",
    "        for i,dd in enumerate(datasetname):\n",
    "            sz = len(fid[dd].shape)\n",
    "            if sz==2:\n",
    "                out[i] = np.array(fid[dd][::rr[0],::rr[1]])\n",
    "            elif sz==3:\n",
    "                out[i] = np.array(fid[dd][::rr[0],::rr[1],::rr[2]])\n",
    "    else:\n",
    "        sz = len(fid[datasetname].shape)\n",
    "        if sz==2:\n",
    "            out = np.array(fid[datasetname][::rr[0],::rr[1]])\n",
    "        elif sz==3:\n",
    "            out = np.array(fid[datasetname][::rr[0],::rr[1],::rr[2]])\n",
    "    return out\n",
    "\n",
    "def writeh5(filename, dtarray, datasetname='main'): \n",
    "    fid=h5py.File(filename,'w')                                                                      \n",
    "    if isinstance(datasetname, (list,)):                                                             \n",
    "        for i,dd in enumerate(datasetname):                                                          \n",
    "            ds = fid.create_dataset(dd, dtarray[i].shape, compression=\"gzip\", dtype=dtarray[i].dtype)\n",
    "            ds[:] = dtarray[i]                                                                       \n",
    "    else:                                                                                            \n",
    "        ds = fid.create_dataset(datasetname, dtarray.shape, compression=\"gzip\", dtype=dtarray.dtype) \n",
    "        ds[:] = dtarray                                                                              \n",
    "    fid.close()\n",
    "    \n",
    "def squeezeto255(dtarray):\n",
    "    \"\"\"\n",
    "    To process Dyer17's dataset.\n",
    "    Given a volume, scale all the voxels into the range of (0, 255).\n",
    "    \"\"\"\n",
    "    volume_min = np.min(dtarray)\n",
    "    # First make all voxel positive, then make the range into (0, 255) \n",
    "    volume = -1.0 * volume_min + dtarray\n",
    "    volume_max = np.max(volume)\n",
    "    volume = (255.0 / volume_max) * volume\n",
    "    return volume\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1volume = readh5('V1_img.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1volume_squeezed = squeezeto255(V1volume) #min=-200, max=105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeh5('V1_img_255.h5', V1volume_squeezed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1volume = readh5('V1_img_255.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-io",
   "language": "python",
   "name": "dataio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
